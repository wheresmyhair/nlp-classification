TextRCNN (BiLSTM+Pooling)
Model(
  (embedding): Embedding(1957, 300, padding_idx=1956)
  (lstm): LSTM(300, 256, batch_first=True, dropout=0.8, bidirectional=True)
  (maxpool): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)
  (fc): Linear(in_features=812, out_features=2, bias=True)
)


>>> train(config, model, train_iter, dev_iter, test_iter)
Epoch [1/100]
Iter:      0,  Train Loss:  0.12,  Train Acc: 100.00%,  Val Loss:  0.84,                 Val Acc: 78.12%,  Time: 0:00:00 *
Epoch [2/100]
Epoch [3/100]
Epoch [4/100]
Epoch [5/100]
Epoch [6/100]
Epoch [7/100]
Epoch [8/100]
Epoch [9/100]
Epoch [10/100]
Epoch [11/100]
Iter:    100,  Train Loss: 0.071,  Train Acc: 98.44%,  Val Loss:  0.31,                 Val Acc: 87.50%,  Time: 0:00:02 *
Epoch [12/100]
Epoch [13/100]
Epoch [14/100]
Epoch [15/100]
Epoch [16/100]
Epoch [17/100]
Epoch [18/100]
Epoch [19/100]
Epoch [20/100]
Epoch [21/100]
Iter:    200,  Train Loss: 0.0021,  Train Acc: 100.00%,  Val Loss:  0.41,                 Val Acc: 88.28%,  Time: 0:00:04
Epoch [22/100]
Epoch [23/100]
Epoch [24/100]
Epoch [25/100]
Epoch [26/100]
Epoch [27/100]
Epoch [28/100]
Epoch [29/100]
Epoch [30/100]
Epoch [31/100]
Iter:    300,  Train Loss: 0.00045,  Train Acc: 100.00%,  Val Loss:  0.64,                 Val Acc: 88.28%,  Time: 0:00:06
Epoch [32/100]
Epoch [33/100]
Epoch [34/100]
Epoch [35/100]
Epoch [36/100]
Epoch [37/100]
Epoch [38/100]
Epoch [39/100]
Epoch [40/100]
Epoch [41/100]
Iter:    400,  Train Loss: 0.0011,  Train Acc: 100.00%,  Val Loss:  0.55,                 Val Acc: 85.16%,  Time: 0:00:08
Epoch [42/100]
Epoch [43/100]
Epoch [44/100]
Epoch [45/100]
Epoch [46/100]
Epoch [47/100]
Epoch [48/100]
Epoch [49/100]
Epoch [50/100]
Epoch [51/100]
Iter:    500,  Train Loss: 0.00047,  Train Acc: 100.00%,  Val Loss:  0.61,                 Val Acc: 86.72%,  Time: 0:00:10
Epoch [52/100]
Epoch [53/100]
Epoch [54/100]
Epoch [55/100]
Epoch [56/100]
Epoch [57/100]
Epoch [58/100]
Epoch [59/100]
Epoch [60/100]
Epoch [61/100]
Iter:    600,  Train Loss: 0.00021,  Train Acc: 100.00%,  Val Loss:  0.67,                 Val Acc: 88.28%,  Time: 0:00:12
Epoch [62/100]
Epoch [63/100]
Epoch [64/100]
Epoch [65/100]
Epoch [66/100]
Epoch [67/100]
Epoch [68/100]
Epoch [69/100]
Epoch [70/100]
Epoch [71/100]
Iter:    700,  Train Loss: 0.00013,  Train Acc: 100.00%,  Val Loss:   0.7,                 Val Acc: 87.50%,  Time: 0:00:14
Epoch [72/100]
Epoch [73/100]
Epoch [74/100]
Epoch [75/100]
Epoch [76/100]
Epoch [77/100]
Epoch [78/100]
Epoch [79/100]
Epoch [80/100]
Epoch [81/100]
Iter:    800,  Train Loss: 9.1e-05,  Train Acc: 100.00%,  Val Loss:  0.74,                 Val Acc: 87.50%,  Time: 0:00:16
Epoch [82/100]
Epoch [83/100]
Epoch [84/100]
Epoch [85/100]
Epoch [86/100]
Epoch [87/100]
Epoch [88/100]
Epoch [89/100]
Epoch [90/100]
Epoch [91/100]
Iter:    900,  Train Loss:   0.1,  Train Acc: 96.09%,  Val Loss:  0.62,                 Val Acc: 81.25%,  Time: 0:00:18
Epoch [92/100]
Epoch [93/100]
Epoch [94/100]
Epoch [95/100]
Epoch [96/100]
Epoch [97/100]
Epoch [98/100]
Epoch [99/100]
Epoch [100/100]
Test Loss:   0.4,  Test Acc: 85.16%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

          金融     0.9551    0.8500    0.8995       100
          其他     0.6154    0.8571    0.7164        28

    accuracy                         0.8516       128
   macro avg     0.7852    0.8536    0.8079       128
weighted avg     0.8808    0.8516    0.8594       128

Confusion Matrix...
[[85 15]
 [ 4 24]]
Time usage: 0:00:00